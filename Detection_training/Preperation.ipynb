{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing to compute with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating c:\\dev\\DHBW\\Studienarbeit\\Detection_training\\Tensorflow\\workspace\\images\n",
      "Creating c:\\dev\\DHBW\\Studienarbeit\\Detection_training\\Tensorflow\\workspace\\images\\collected_images\n",
      "Creating c:\\dev\\DHBW\\Studienarbeit\\Detection_training\\Tensorflow\\workspace\\images\\collected_images_resized\n",
      "Creating c:\\dev\\DHBW\\Studienarbeit\\Detection_training\\Tensorflow\\workspace\\images\\trainset\n",
      "Creating c:\\dev\\DHBW\\Studienarbeit\\Detection_training\\Tensorflow\\workspace\\images\\testset\n",
      "Creating c:\\dev\\DHBW\\Studienarbeit\\Detection_training\\Tensorflow\\workspace\\images\\devset\n",
      "Creating c:\\dev\\DHBW\\Studienarbeit\\Detection_training\\Tensorflow\\workspace\n",
      "Creating c:\\dev\\DHBW\\Studienarbeit\\Detection_training\\Tensorflow\\scripts\n",
      "Creating c:\\dev\\DHBW\\Studienarbeit\\Detection_training\\Tensorflow\\models\n",
      "Creating c:\\dev\\DHBW\\Studienarbeit\\Detection_training\\Tensorflow\\workspace\\annotations\n",
      "Creating c:\\dev\\DHBW\\Studienarbeit\\Detection_training\\Tensorflow\\workspace\\models\n",
      "Creating c:\\dev\\DHBW\\Studienarbeit\\Detection_training\\Tensorflow\\workspace\\pre-trained-models\n",
      "Creating c:\\dev\\DHBW\\Studienarbeit\\Detection_training\\Tensorflow\\protoc\n",
      "Creating c:\\dev\\DHBW\\Studienarbeit\\Detection_training\\Tensorflow\\labelimg\n"
     ]
    }
   ],
   "source": [
    "import Tensorflow.scripts.Paths as Paths\n",
    "import os\n",
    "\n",
    "# setting up the paths\n",
    "paths = Paths.WorkingPaths\n",
    "paths.setup_paths()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labeling own images with Label Studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install label-studio --user"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!label-studio start"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: when finished you will export them to Pascal VOC Annotation and manually copy them into the `collected_images` directory in the `Tensorflow/workspace/images` directory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading images from other sources\n",
    "\n",
    "First i downloaded the images and xml-annotations from this [github repository](https://github.com/datitran/raccoon_dataset).\n",
    "\n",
    "You can simply copy them in the `collected_images` directory which should be available under the `Tensorflow/workspace/images` directory. Now you should have about 200 images from Racoons pretty low number isn't it?\n",
    "\n",
    "Well thats true so we will increase them. But for a first evaluation of choosing the right pretrained model it should be fine to use. Especially if you want to use Google Colab since you most likely only train for a couple of hours before you run out of GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming the files to match the others\n",
    "import uuid\n",
    "\n",
    "renamed: dict[str, str] = {}\n",
    "for filenames in os.listdir(paths.COLLECTED_IMAGES_PATH):\n",
    "    filename, ext = os.path.splitext(filenames)\n",
    "    if 'raccoon' in filename:\n",
    "        if ext != '.xml':\n",
    "            # Generate 60 Bit uuid\n",
    "            uuid_ = uuid.uuid4().hex[:16]\n",
    "            renamed.update({filename: uuid_})\n",
    "        os.rename(os.path.join(paths.COLLECTED_IMAGES_PATH, filename + ext), os.path.join(paths.COLLECTED_IMAGES_PATH, renamed[filename] + ext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully converted xml to csv.\n"
     ]
    }
   ],
   "source": [
    "# Convert the xml files to csv\n",
    "# this will also convert your images from Label Studio\n",
    "!python {Paths.XML_TO_CSV} -i {paths.COLLECTED_IMAGES_PATH} -o {Paths.CSV_FILE}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that make sure that the Label is Raccoon and not raccoon"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download openimages from google\n",
    "\n",
    "We will use [fiftyone](https://docs.voxel51.com/user_guide/dataset_zoo/datasets.html#open-images-v7) to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fiftyone\n",
    "\n",
    "import fiftyone as fo\n",
    "\n",
    "# Customize where zoo datasets are downloaded\n",
    "fo.config.dataset_zoo_dir = paths.IMAGE_PATH\n",
    "\n",
    "# This will take a hell lot of time since the .csv file will be downloaded for all labels and images (train has 2.2 GB)\n",
    "dataset = fo.zoo.load_zoo_dataset(\n",
    "    \"open-images-v7\",\n",
    "    label_types=[\"detections\"],\n",
    "    classes=[\"Raccoon\"]\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will need to preprocess that huge CSV files and combine them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining classes from: \"c:\\\\dev\\\\DHBW\\\\Studienarbeit\\\\Detection_training\\\\Tensorflow\\\\workspace\\\\images\\\\open-images-v7\\\\train\"\n",
      "Found allowed label: \"Raccoon\"\n",
      "Obtaining detections from: \"c:\\\\dev\\\\DHBW\\\\Studienarbeit\\\\Detection_training\\\\Tensorflow\\\\workspace\\\\images\\\\open-images-v7\\\\train\"\n",
      "Found 381 valid detections\n",
      "Found existing output file. Joining it now.\n",
      "Wrote 381 new records. All detections count: 598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Finished release [optimized] target(s) in 0.16s\n",
      "     Running `Tensorflow\\scripts\\csv_conv\\target\\release\\csv_conv.exe -i c:\\dev\\DHBW\\Studienarbeit\\Detection_training\\Tensorflow\\workspace\\images\\open-images-v7\\train -o c:\\dev\\DHBW\\Studienarbeit\\Detection_training\\Tensorflow\\workspace\\images\\collected_images -l Raccoon`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining classes from: \"c:\\\\dev\\\\DHBW\\\\Studienarbeit\\\\Detection_training\\\\Tensorflow\\\\workspace\\\\images\\\\open-images-v7\\\\test\"\n",
      "Found allowed label: \"Raccoon\"\n",
      "Obtaining detections from: \"c:\\\\dev\\\\DHBW\\\\Studienarbeit\\\\Detection_training\\\\Tensorflow\\\\workspace\\\\images\\\\open-images-v7\\\\test\"\n",
      "Found 89 valid detections\n",
      "Found existing output file. Joining it now.\n",
      "Wrote 89 new records. All detections count: 687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Finished release [optimized] target(s) in 0.11s\n",
      "     Running `Tensorflow\\scripts\\csv_conv\\target\\release\\csv_conv.exe -i c:\\dev\\DHBW\\Studienarbeit\\Detection_training\\Tensorflow\\workspace\\images\\open-images-v7\\test -o c:\\dev\\DHBW\\Studienarbeit\\Detection_training\\Tensorflow\\workspace\\images\\collected_images -l Raccoon`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining classes from: \"c:\\\\dev\\\\DHBW\\\\Studienarbeit\\\\Detection_training\\\\Tensorflow\\\\workspace\\\\images\\\\open-images-v7\\\\validation\"\n",
      "Found allowed label: \"Raccoon\"\n",
      "Obtaining detections from: \"c:\\\\dev\\\\DHBW\\\\Studienarbeit\\\\Detection_training\\\\Tensorflow\\\\workspace\\\\images\\\\open-images-v7\\\\validation\"\n",
      "Found 28 valid detections\n",
      "Found existing output file. Joining it now.\n",
      "Wrote 28 new records. All detections count: 715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Finished release [optimized] target(s) in 0.10s\n",
      "     Running `Tensorflow\\scripts\\csv_conv\\target\\release\\csv_conv.exe -i c:\\dev\\DHBW\\Studienarbeit\\Detection_training\\Tensorflow\\workspace\\images\\open-images-v7\\validation -o c:\\dev\\DHBW\\Studienarbeit\\Detection_training\\Tensorflow\\workspace\\images\\collected_images -l Raccoon`\n"
     ]
    }
   ],
   "source": [
    "labels = \"\"\n",
    "for label in Paths.LABELS:\n",
    "    labels +=\" -l \" + label[\"name\"]\n",
    "\n",
    "!cargo run --manifest-path={Paths.CSV_CONV} --release -- -i {Paths.OPEN_IMAGES_TRAIN} -o {paths.COLLECTED_IMAGES_PATH} {labels}\n",
    "!cargo run --manifest-path={Paths.CSV_CONV} --release -- -i {Paths.OPEN_IMAGES_TEST} -o {paths.COLLECTED_IMAGES_PATH} {labels}\n",
    "!cargo run --manifest-path={Paths.CSV_CONV} --release -- -i {Paths.OPEN_IMAGES_VALIDATION} -o {paths.COLLECTED_IMAGES_PATH} {labels}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the images for better performance during trainings.\n",
    "\n",
    "downscaling thm now is better than when TensorFlow would do it on runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imutils in c:\\users\\lmueller\\.conda\\envs\\study\\lib\\site-packages (0.5.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "starting to resize detection in csv file\n",
      "Writing output file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Finished release [optimized] target(s) in 0.15s\n",
      "     Running `Tensorflow\\scripts\\resize_csv\\target\\release\\resize_csv.exe -i c:\\dev\\DHBW\\Studienarbeit\\Detection_training\\Tensorflow\\workspace\\images\\collected_images\\detections.csv -o c:\\dev\\DHBW\\Studienarbeit\\Detection_training\\Tensorflow\\workspace\\images\\collected_images_resized\\detections.csv -r 320`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized 612 images with option grayscale=False\n"
     ]
    }
   ],
   "source": [
    "from Tensorflow.scripts.preprocessing_data import resize_images\n",
    "%pip install imutils\n",
    "\n",
    "!cargo run --manifest-path={Paths.CSV_RESIZE} --release -- -i {Paths.CSV_FILE} -o {Paths.CSV_FILE_RESIZED} -r 320\n",
    "\n",
    "resize_images(paths.COLLECTED_IMAGES_PATH, paths.RESIZED_IMAGES_PATH, 320)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split up the resized images into Dev- Test- and Trainset\n",
    "\n",
    "You can do it manually or using the following Code snippet to do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 520 records in \"c:\\\\dev\\\\DHBW\\\\Studienarbeit\\\\Detection_training\\\\Tensorflow\\\\workspace\\\\images\\\\trainset\\\\detections.csv\"\n",
      "Wrote 61 records in \"c:\\\\dev\\\\DHBW\\\\Studienarbeit\\\\Detection_training\\\\Tensorflow\\\\workspace\\\\images\\\\testset\\\\detections.csv\"\n",
      "Wrote 31 records in \"c:\\\\dev\\\\DHBW\\\\Studienarbeit\\\\Detection_training\\\\Tensorflow\\\\workspace\\\\images\\\\devset\\\\detections.csv\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    Finished release [optimized] target(s) in 0.13s\n",
      "     Running `Tensorflow\\scripts\\split_dataset\\target\\release\\split_dataset.exe -i c:\\dev\\DHBW\\Studienarbeit\\Detection_training\\Tensorflow\\workspace\\images\\collected_images_resized -o c:\\dev\\DHBW\\Studienarbeit\\Detection_training\\Tensorflow\\workspace\\images`\n"
     ]
    }
   ],
   "source": [
    "# for some reasons bugged. I can not directly use the command\n",
    "!cargo run --manifest-path={Paths.SPLIT_DATASET} --release -- -i {paths.RESIZED_IMAGES_PATH} -o {paths.IMAGE_PATH}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compress Datasets to use on Google Colab and on other platforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths will be relative in tar files. The tar command would take absolute paths and by using the .tar file paths would be wrong.\n",
    "trainset = os.path.join('Tensorflow', 'workspace', 'images', 'trainset')\n",
    "dataset = os.path.join('Tensorflow', 'workspace', 'images', Paths.DATASET_NAME)\n",
    "testset = os.path.join('Tensorflow', 'workspace', 'images', 'testset')\n",
    "devset = os.path.join('Tensorflow', 'workspace', 'images', 'devset')\n",
    "\n",
    "command = \"{} {} {} {}\".format(dataset, trainset, testset, devset)\n",
    "!tar -czf {command}\n",
    "# If you want to export the dataset you need to manually copy it"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "23fe2c85cd4f0d6d4635f96a95cebf9dfe9e68035876b476cfa94a759db7b2c2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
