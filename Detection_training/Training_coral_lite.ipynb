{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhyQxxzJIab3"
      },
      "source": [
        "# Clone my repo to get all paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKu8-187Iab9",
        "outputId": "c24b5afb-54c7-4f3e-f277-bc6f5990ca99"
      },
      "outputs": [],
      "source": [
        "# So Colab can use the python files...\n",
        "!git clone --single-branch -b develop https://github.com/muellevin/Studienarbeit.git\n",
        "%cd Studienarbeit/Detection_training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ex0KGMPNIacA"
      },
      "source": [
        " and set all up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpSnFjOsIacC",
        "outputId": "9652a37a-c068-4a1c-c281-a035f5d4210d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import Tensorflow.scripts.Paths as pp\n",
        "\n",
        "CUSTOM_MODEL_NAME = 'raccoonModel_50ep_b16_efficientdetlit0_17070'\n",
        "PRETRAINED_MODEL_NAME = 'ssdlite_mobiledet_edgetpu_320x320_coco_2020_05_19'\n",
        "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/ssdlite_mobiledet_edgetpu_320x320_coco_2020_05_19.tar.gz'\n",
        "\n",
        "\n",
        "paths = pp.paths\n",
        "paths.setup_paths()\n",
        "\n",
        "OUTPUT_PATH = os.path.join(paths.MODEL_PATH, CUSTOM_MODEL_NAME, 'export')\n",
        "SAVED_MODEL = os.path.join(OUTPUT_PATH, 'saved_model')\n",
        "TFLITE_EXPORT = os.path.join(OUTPUT_PATH, 'tfliteexport')\n",
        "CHECKPOINT_PATH = os.path.join(paths.MODEL_PATH, CUSTOM_MODEL_NAME)\n",
        "\n",
        "os.makedirs(CHECKPOINT_PATH, exist_ok=True)\n",
        "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "PIPELINE_CONFIG = os.path.join(paths.MODEL_PATH, CUSTOM_MODEL_NAME, 'pipeline.config')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Setup for SSDLite MobileDet (TF1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -U numpy==1.19.5\n",
        "!pip install -U pycocotools==2.0.1\n",
        "!pip install tensorflow==1.15\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# building tensorflow\n",
        "! pip install tf_slim\n",
        "\n",
        "# Download TensorFlow Object detection library if not available\n",
        "if not os.path.exists(os.path.join(paths.APIMODEL_PATH, 'research', 'object_detection')):\n",
        "    command = \"git clone https://github.com/tensorflow/models {}\".format(paths.APIMODEL_PATH)\n",
        "\n",
        "    !{command}\n",
        "\n",
        "# install TensorFlow\n",
        "if os.name=='posix':  \n",
        "    !apt-get install protobuf-compiler\n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
        "    \n",
        "if os.name=='nt':\n",
        "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
        "    wget.download(url)\n",
        "    !move protoc-3.15.6-win64.zip {paths.PROTOC_PATH}\n",
        "    !cd {paths.PROTOC_PATH} && tar -xf protoc-3.15.6-win64.zip\n",
        "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths.PROTOC_PATH, 'bin'))\n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
        "    !cd Tensorflow/models/research/slim && pip install -e . "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify it\n",
        "VERIFICATION_SCRIPT = os.path.join(paths.APIMODEL_PATH, 'research', 'object_detection', 'builders', 'model_builder_test.py')\n",
        "# Verify Installation\n",
        "!python {VERIFICATION_SCRIPT}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(pp.LABELMAP, 'w') as f:\n",
        "    for label in pp.LABELS:\n",
        "        f.write('item { \\n')\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\n",
        "        f.write('}\\n')\n",
        "\n",
        "!python {pp.TF_RECORD_SCRIPT} -img_path {paths.TRAINSET_PATH} -output_path {pp.TRAINSET_RECORD_PATH}\n",
        "!python {pp.TF_RECORD_SCRIPT} -img_path {paths.TESTSET_PATH} -output_path {pp.TESTSET_RECORD_PATH}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare for training\n",
        "import tensorflow as tf\n",
        "from google.protobuf import text_format\n",
        "from object_detection.protos import pipeline_pb2\n",
        "import os\n",
        "pipeline = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "\n",
        "config_path = os.path.join(pp.APIMODEL_PATH, 'research', 'object_detection', 'samples', 'configs', 'ssdlite_mobiledet_edgetpu_320x320_coco_sync_4x4.config')\n",
        "with tf.gfile.GFile(config_path, \"r\") as f:\n",
        "    proto_str = f.read()\n",
        "    text_format.Merge(proto_str, pipeline)\n",
        "\n",
        "pipeline.train_input_reader.tf_record_input_reader.input_path[:] = [pp.TRAINSET_RECORD_PATH]\n",
        "pipeline.train_input_reader.label_map_path = pp.LABELMAP\n",
        "pipeline.eval_input_reader[0].tf_record_input_reader.input_path[:] = [pp.TESTSET_RECORD_PATH]\n",
        "pipeline.eval_input_reader[0].label_map_path = pp.LABELMAP\n",
        "pipeline.train_config.fine_tune_checkpoint = os.path.join(paths.PRETRAINED_MODEL_PATH, PRETRAINED_MODEL_NAME, 'fp32', 'model.ckpt')\n",
        "pipeline.train_config.batch_size = 16\n",
        "pipeline.train_config.num_steps = 50000\n",
        "pipeline.model.ssd.num_classes = len(pp.LABELS)\n",
        "# Enable ssdlite, this should already be enabled in the config we downloaded, but this is just to make sure.\n",
        "pipeline.model.ssd.box_predictor.convolutional_box_predictor.kernel_size = 3\n",
        "pipeline.model.ssd.box_predictor.convolutional_box_predictor.use_depthwise = True\n",
        "pipeline.model.ssd.feature_extractor.use_depthwise = True\n",
        "# Quantization Aware Training\n",
        "pipeline.graph_rewriter.quantization.delay = 0\n",
        "pipeline.graph_rewriter.quantization.weight_bits = 8\n",
        "pipeline.graph_rewriter.quantization.activation_bits = 8\n",
        "\n",
        "config_text = text_format.MessageToString(pipeline)                                                                                                                                                                                                        \n",
        "with tf.gfile.Open(PIPELINE_CONFIG, \"wb\") as f:\n",
        "    f.write(config_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train it\n",
        "from datetime import datetime\n",
        "start = datetime.now()\n",
        "\n",
        "TRAINING_SCRIPT = os.path.join(paths.APIMODEL_PATH, 'research', 'object_detection', 'model_main.py')\n",
        "command = \"python {} --model_dir={} --pipeline_config_path={}\".format(TRAINING_SCRIPT, CHECKPOINT_PATH, PIPELINE_CONFIG)\n",
        "print(command)\n",
        "!{command}\n",
        "\n",
        "end = datetime.now()\n",
        "duration = end - start\n",
        "seconds_in_hour = 60 * 60\n",
        "hours, seconds = divmod(duration.seconds, seconds_in_hour)\n",
        "minutes = int(seconds / 60)\n",
        "print('TRAINING TIME:', str(hours) + ':' + str(minutes if minutes > 10 else '%02d' % minutes))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Export it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "FREEZE_SCRIPT = os.path.join(paths.APIMODEL_PATH, 'research', 'object_detection', 'export_inference_graph.py ')\n",
        "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_prefix={} --output_directory={} --add_postprocessing_op=true\".format(FREEZE_SCRIPT , PIPELINE_CONFIG, os.path.join(CHECKPOINT_PATH, 'model.ckpt-50000'), OUTPUT_PATH)\n",
        "!{command}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# to tflite\n",
        "# Convert to a tflite file (for CPU)\n",
        "! tflite_convert \\\n",
        "  --output_file={os.path.join(TFLITE_EXPORT, CUSTOM_MODEL_NAME +'.tflite')} \\\n",
        "  --graph_def_file={os.path.join(OUTPUT_PATH, 'tflite_graph.pb')} \\\n",
        "  --inference_type=QUANTIZED_UINT8 \\\n",
        "  --input_arrays=\"normalized_input_image_tensor\" \\\n",
        "  --output_arrays=\"TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3\" \\\n",
        "  --mean_values=128 \\\n",
        "  --std_dev_values=128 \\\n",
        "  --input_shapes=1,320,320,3 \\\n",
        "  --allow_custom_ops"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vf6uc-qeIacD"
      },
      "source": [
        "# Setup for EfficientDet-Lite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhihu1TMIacE",
        "outputId": "5ea801bb-9b53-48e4-9e28-c4579a344f75"
      },
      "outputs": [],
      "source": [
        "!pip install -q tflite-model-maker\n",
        "!pip install tensorflow==2.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0J8QBUaIacE",
        "outputId": "d1bdda1a-7e27-4598-e456-088d7640ba1b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from tflite_model_maker.config import ExportFormat\n",
        "from tflite_model_maker import model_spec\n",
        "from tflite_model_maker import object_detector\n",
        "\n",
        "import tensorflow as tf\n",
        "assert tf.__version__.startswith('2')\n",
        "\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "from absl import logging\n",
        "logging.set_verbosity(logging.ERROR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzTbPGCaIacF"
      },
      "source": [
        "# Upload images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3QsF8ciIacG",
        "outputId": "956072da-c319-4789-958b-5caa9334ff5f"
      },
      "outputs": [],
      "source": [
        "GOOGLE_DRIVE_PATH = '/content/drive/MyDrive/Studienarbeit'\n",
        "\n",
        "if os.name =='posix':\n",
        "    from google.colab import drive\n",
        "\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import shutil\n",
        "shutil.copy(os.path.join(GOOGLE_DRIVE_PATH, pp.DATASET_NAME), paths.IMAGE_PATH)\n",
        "\n",
        "if os.path.exists(pp.DATASET):\n",
        "  !tar -zxvf {pp.DATASET}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cv2LyVnQIacH"
      },
      "source": [
        "To lazy to do the  conversion again locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2aG_OWgTIacI"
      },
      "outputs": [],
      "source": [
        "from Tensorflow.scripts.csv_to_voc import convert_csv_to_voc\n",
        "\n",
        "\n",
        "convert_csv_to_voc(os.path.join(paths.TRAINSET_PATH, pp.CSV_FILE_NAME), paths.TRAINSET_PATH)\n",
        "convert_csv_to_voc(os.path.join(paths.TESTSET_PATH, pp.CSV_FILE_NAME), paths.TESTSET_PATH)\n",
        "convert_csv_to_voc(os.path.join(paths.DEVSET_PATH, pp.CSV_FILE_NAME), paths.DEVSET_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngXPHcmAIacJ"
      },
      "outputs": [],
      "source": [
        "label_map = {} # dictionary to store class names\n",
        "for label in pp.LABELS:\n",
        "    label_map[label['id']] = label['name']\n",
        "# prepare data for training\n",
        "train_data = object_detector.DataLoader.from_pascal_voc(\n",
        "        paths.TRAINSET_PATH, paths.TRAINSET_PATH, label_map=label_map)\n",
        "validation_data = object_detector.DataLoader.from_pascal_voc(\n",
        "        paths.TESTSET_PATH, paths.TESTSET_PATH, label_map=label_map)\n",
        "test_data = object_detector.DataLoader.from_pascal_voc(\n",
        "        paths.DEVSET_PATH, paths.DEVSET_PATH, label_map=label_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3w4b-wYiIacK"
      },
      "outputs": [],
      "source": [
        "# choose model\n",
        "spec = object_detector.EfficientDetLite0Spec()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSeRzHfNIacK",
        "outputId": "e55e90fa-a9ab-4a18-f7b5-8a1d009fb662"
      },
      "outputs": [],
      "source": [
        "# train model\n",
        "model = object_detector.create(train_data=train_data, \n",
        "                               model_spec=spec, \n",
        "                               validation_data=validation_data, \n",
        "                               epochs=34, \n",
        "                               batch_size=16, \n",
        "                               train_whole_model=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_ijB5JiIacL",
        "outputId": "b94040ea-6981-4a56-ae4f-c6210f0bdad0"
      },
      "outputs": [],
      "source": [
        "# evaluate\n",
        "model.evaluate(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPsz0BlPIacL",
        "outputId": "548bf407-79cb-4078-cd1a-3abe4dab9072"
      },
      "outputs": [],
      "source": [
        "# convert to tflite\n",
        "model.export(export_dir=TFLITE_EXPORT, tflite_filename=CUSTOM_MODEL_NAME + '.tflite', label_filename='labels.txt',\n",
        "             export_format=[ExportFormat.TFLITE, ExportFormat.LABEL])\n",
        "\n",
        "# and evaluate this\n",
        "model.evaluate_tflite(os.path.join(TFLITE_EXPORT, CUSTOM_MODEL_NAME + '.tflite'), test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr_eL-kHIacM"
      },
      "source": [
        "# Compile for TPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ew96z97WIacR",
        "outputId": "b25beef9-850a-4576-cddd-a82be57a894f"
      },
      "outputs": [],
      "source": [
        "# Compile for TPU\n",
        "# ! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
        "\n",
        "# ! echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
        "\n",
        "# ! sudo apt-get update\n",
        "\n",
        "# ! sudo apt-get install edgetpu-compiler\n",
        "\n",
        "NUMBER_OF_TPUS =  1\n",
        "\n",
        "!edgetpu_compiler {os.path.join(TFLITE_EXPORT, CUSTOM_MODEL_NAME + '.tflite')} -d --num_segments=$NUMBER_OF_TPUS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lxJyixOIacS",
        "outputId": "b1228297-67a0-4d79-8420-89e0cc276613"
      },
      "outputs": [],
      "source": [
        "# zip and download\n",
        "!zip -r {os.path.join(GOOGLE_DRIVE_PATH, CUSTOM_MODEL_NAME + '.zip')} {TFLITE_EXPORT}"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "study",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "23fe2c85cd4f0d6d4635f96a95cebf9dfe9e68035876b476cfa94a759db7b2c2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
